{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Código procedente de Kaggle.\n",
    "***Autor:***\n",
    "* **LIU SHI CAI · 5Y AGO**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install keras\n",
    "# %pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_uuid": "e5d71ebffaaa868cf3173b24a32fb478cf8b0d16"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "# import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# import matplotlib.pyplot as plt\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.optimizers import SGD\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_uuid": "7161040562b0e2263dea00d7955878d8095cc2d3"
   },
   "outputs": [],
   "source": [
    "# leemos los archivos CSV utilizando la biblioteca pandas.\n",
    "# Los datos se almacenan en dos DataFrames: train_df y test_df.\n",
    "train_df = pd.read_csv(\"train.csv\")\n",
    "test_df = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "86d2dfb45d02e1b87efdfec71850d51d0ba49bf7"
   },
   "outputs": [],
   "source": [
    "# Se convierten los DataFrames train_df y test_df en matrices NumPy utilizando el método \".values\". \n",
    "# Extrae los valores de los DataFrames y los convierte en matrices NumPy.\n",
    "train_data = train_df.values\n",
    "test_data = test_df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "4b34d23b93170bbb6731fcc24df61c94254bbb82"
   },
   "outputs": [],
   "source": [
    "# Separamos los datos de entrenamiento en dos matrices NumPy diferentes: labels y train.\n",
    "labels = train_data[:,0]\n",
    "\n",
    "# Se dividen por 255 para realizar una normalización de los píxeles, asumiendo que los valores originales están en el rango de 0 a 255.\n",
    "train = train_data[:,1:]/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "ae485338a42fccce0650a635e3df713b4539f1a4"
   },
   "outputs": [],
   "source": [
    "# La función to_categorical de Keras se utiliza para convertir las etiquetas numéricas en codificación one-hot.\n",
    "dummy_y = keras.utils.to_categorical(labels)\n",
    "\n",
    "# La función train_test_split de la biblioteca scikit-learn se utiliza para dividir los datos en conjuntos de entrenamiento y prueba.\n",
    "# Se utiliza un tamaño de prueba del 10% (test_size=0.1).\n",
    "# Se establece una semilla aleatoria (random_state=166) para que la división sea reproducible.\n",
    "# La opción stratify=labels garantiza que las proporciones de las clases se mantengan en los conjuntos de entrenamiento y prueba.\n",
    "x_train, x_test, y_train, y_test = train_test_split(train, dummy_y, test_size=0.1, random_state=166,stratify=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_uuid": "7f04d72367c7fe501dfbf7ff64d5ed64c04c81e7"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Las matrices x_train y x_test se remodelan utilizando el método reshape para adaptarse a un formato específico antes de ser utilizadas \n",
    "en un modelo de clasificación de imágenes.\n",
    "\n",
    "La forma original de los datos en MNIST es de imágenes en escala de grises de 28x28 píxeles. Sin embargo, para entrenar un modelo de \n",
    "aprendizaje profundo, generalmente se requiere que los datos estén en un formato específico, que es\n",
    "[número_de_ejemplos, ancho, alto, canales].\n",
    "\n",
    "En este caso, se está agregando una dimensión adicional a los datos utilizando reshape. El primer argumento x_train.shape[0] indica el número\n",
    "de ejemplos de entrenamiento, y luego se especifica la forma deseada de las imágenes, que es (28, 28, 1). La dimensión adicional de 1 se refiere\n",
    "al canal de color y representa la escala de grises.\n",
    "'''\n",
    "# Remodelar los datos de entrenamiento y prueba.\n",
    "x_train = x_train.reshape(x_train.shape[0],28,28, 1)\n",
    "\n",
    "# El ancho y alto son 28x28 píxeles.\n",
    "# Y los canales son 1, que representa la escala de grises.\n",
    "x_test = x_test.reshape(x_test.shape[0],28,28, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_uuid": "079cfbd31af1406537c3698a3eaf1c0ddb77e11e",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 28, 28, 64)        640       \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 28, 28, 64)        36928     \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 28, 28, 128)       73856     \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 1, 1, 128)         12845184  \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 128)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 256)               33024     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 256)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                2570      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 12,992,202\n",
      "Trainable params: 12,992,202\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "296/296 [==============================] - ETA: 0s - loss: 0.5431 - accuracy: 0.8358\n",
      "Epoch 1: val_accuracy improved from -inf to 0.95214, saving model to convolutional_minist.h5\n",
      "296/296 [==============================] - 2836s 10s/step - loss: 0.5431 - accuracy: 0.8358 - val_loss: 0.1539 - val_accuracy: 0.9521\n",
      "Epoch 2/10\n",
      "296/296 [==============================] - ETA: 0s - loss: 0.1389 - accuracy: 0.9596 \n",
      "Epoch 2: val_accuracy improved from 0.95214 to 0.97381, saving model to convolutional_minist.h5\n",
      "296/296 [==============================] - 3228s 11s/step - loss: 0.1389 - accuracy: 0.9596 - val_loss: 0.0820 - val_accuracy: 0.9738\n",
      "Epoch 3/10\n",
      "296/296 [==============================] - ETA: 0s - loss: 0.0858 - accuracy: 0.9742 \n",
      "Epoch 3: val_accuracy improved from 0.97381 to 0.97929, saving model to convolutional_minist.h5\n",
      "296/296 [==============================] - 3328s 11s/step - loss: 0.0858 - accuracy: 0.9742 - val_loss: 0.0679 - val_accuracy: 0.9793\n",
      "Epoch 4/10\n",
      "296/296 [==============================] - ETA: 0s - loss: 0.0604 - accuracy: 0.9813 \n",
      "Epoch 4: val_accuracy improved from 0.97929 to 0.98262, saving model to convolutional_minist.h5\n",
      "296/296 [==============================] - 3401s 11s/step - loss: 0.0604 - accuracy: 0.9813 - val_loss: 0.0526 - val_accuracy: 0.9826\n",
      "Epoch 5/10\n",
      "296/296 [==============================] - ETA: 0s - loss: 0.0462 - accuracy: 0.9862 \n",
      "Epoch 5: val_accuracy did not improve from 0.98262\n",
      "296/296 [==============================] - 3382s 11s/step - loss: 0.0462 - accuracy: 0.9862 - val_loss: 0.0557 - val_accuracy: 0.9812\n",
      "Epoch 6/10\n",
      "296/296 [==============================] - ETA: 0s - loss: 0.0377 - accuracy: 0.9886 \n",
      "Epoch 6: val_accuracy did not improve from 0.98262\n",
      "296/296 [==============================] - 3235s 11s/step - loss: 0.0377 - accuracy: 0.9886 - val_loss: 0.0510 - val_accuracy: 0.9821\n",
      "Epoch 7/10\n",
      "296/296 [==============================] - ETA: 0s - loss: 0.0291 - accuracy: 0.9910\n",
      "Epoch 7: val_accuracy improved from 0.98262 to 0.98333, saving model to convolutional_minist.h5\n",
      "296/296 [==============================] - 2865s 10s/step - loss: 0.0291 - accuracy: 0.9910 - val_loss: 0.0556 - val_accuracy: 0.9833\n",
      "Epoch 8/10\n",
      "296/296 [==============================] - ETA: 0s - loss: 0.0232 - accuracy: 0.9925\n",
      "Epoch 8: val_accuracy improved from 0.98333 to 0.98405, saving model to convolutional_minist.h5\n",
      "296/296 [==============================] - 2891s 10s/step - loss: 0.0232 - accuracy: 0.9925 - val_loss: 0.0542 - val_accuracy: 0.9840\n",
      "Epoch 9/10\n",
      "296/296 [==============================] - ETA: 0s - loss: 0.0188 - accuracy: 0.9939 \n",
      "Epoch 9: val_accuracy improved from 0.98405 to 0.98571, saving model to convolutional_minist.h5\n",
      "296/296 [==============================] - 3099s 10s/step - loss: 0.0188 - accuracy: 0.9939 - val_loss: 0.0491 - val_accuracy: 0.9857\n",
      "Epoch 10/10\n",
      "296/296 [==============================] - ETA: 0s - loss: 0.0153 - accuracy: 0.9948\n",
      "Epoch 10: val_accuracy did not improve from 0.98571\n",
      "296/296 [==============================] - 2746s 9s/step - loss: 0.0153 - accuracy: 0.9948 - val_loss: 0.0508 - val_accuracy: 0.9852\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x24092506e20>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Definimos y entrenamos un modelo de red neuronal convolucional utilizando Keras.\n",
    "\n",
    "\n",
    "# Creamos una instancia del modelo secuencial de Keras, que permite agregar capas de manera secuencial.\n",
    "model = Sequential()\n",
    "\n",
    "# Se define una lista de callbacks, en este caso se utiliza el ModelCheckpoint para guardar el mejor modelo durante el entrenamiento. \n",
    "# El modelo se guarda en el archivo \"convolutional_minist.h5\" basado en la métrica de precisión en la validación (val_acc).\n",
    "callbacks = [keras.callbacks.ModelCheckpoint('convolutional_minist.h5', monitor='val_accuracy', verbose=1, save_best_only=True,\n",
    "                            mode='auto')]\n",
    "\n",
    "'''Se agregan capas convolucionales utilizando la función add() del modelo secuencial. Se utilizan cuatro capas \n",
    "  convolucionales con diferentes tamaños de kernel y funciones de activación 'relu'.\n",
    "'''\n",
    "\n",
    "# La primera capa tiene un tamaño de kernel de (3,3) y recibe la forma de entrada (28,28,1) para imágenes en escala de grises.\n",
    "model.add(Conv2D(64, kernel_size=(3, 3),\n",
    "                 activation='relu',padding='same',\n",
    "                 input_shape=(28,28,1)))\n",
    "\n",
    "# Las siguientes capas convolucionales tienen el mismo tamaño de kernel (3,3) y 'padding' 'same' para mantener el tamaño de la imagen.\n",
    "model.add(Conv2D(64, (3, 3),padding='same', activation='relu'))\n",
    "model.add(Conv2D(128, (3, 3),padding='same', activation='relu'))\n",
    "\n",
    "# La cuarta capa convolucional tiene un tamaño de kernel de (28,28) y se utiliza una activación 'relu'.\n",
    "model.add(Conv2D(128, (28, 28),activation='relu'))\n",
    "\n",
    "# Se agrega una capa de aplanamiento (flatten) para convertir los mapas de características en un vector unidimensional.\n",
    "model.add(Flatten())\n",
    "\n",
    "# Se agrega una capa densa con 256 neuronas y activación 'relu'.\n",
    "model.add(Dense(256, activation='relu'))\n",
    "\n",
    "# Se agrega una capa de dropout con una tasa de dropout del 50% para regularizar el modelo y evitar el sobreajuste.\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# Se agrega una capa densa final con 10 neuronas (correspondientes a las 10 clases de salida). \n",
    "# Una función de activación 'softmax' para la clasificación multiclase.\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "\n",
    "\n",
    "# Función utilizada en Keras para mostrar un resumen del modelo de la red neuronal. \n",
    "# Nos da una descripción de la arquitectura de la red, la forma de entrada y salida de las capa y número de parámetros entrenables del modelo.\n",
    "model.summary()\n",
    "\n",
    "# Se compila el modelo especificando la función de pérdida ('categorical_crossentropy').\n",
    "# Se define además, el optimizador ('sgd' con una tasa de aprendizaje de 0.01 y momentum de 0.9) y las métricas a utilizar ('accuracy').\n",
    "\n",
    "sgd = SGD(learning_rate=0.01, momentum=0.9) # \"lr\" en desuso cambiarlo por \"learning_rate\".\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
    "\n",
    "# Se ajusta el modelo utilizando los datos de entrenamiento.\n",
    "# Se especifica el tamaño del lote, el número de épocas, la verbosidad y los datos de validación (x_test y y_test). \n",
    "# También se pasan los callbacks definidos anteriormente.\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=128,\n",
    "          epochs=10,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test),callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función que se utiliza para cargar los pesos pre-entrenados de un modelo guardado en un archivo HDF5.\n",
    "model.load_weights('convolutional_minist.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_uuid": "d2a33bcb15ac4b5b62cb540cd9cd57e6391a0e2d"
   },
   "outputs": [],
   "source": [
    "# Le damos el formato adecuado a los datos de prueba (test) antes de realizar predicciones con el modelo.\n",
    "# Al realizar esta transformación en los datos de prueba, se asegura que tengan el mismo formato que los datos de entrenamiento.\n",
    "test = test_data.reshape(test_data.shape[0],28,28, 1)/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_uuid": "e1ad38f6523a23cbd84ec324c794ff590c75ed7a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "875/875 [==============================] - 242s 275ms/step\n"
     ]
    }
   ],
   "source": [
    "# Obtenemos las predicciones del modelo sobre los datos de prueba.\n",
    "predict = model.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_uuid": "0724c7fd80af2aae489f0a5469d8a2eeecfd71f0"
   },
   "outputs": [],
   "source": [
    "# Obtenemos las etiquetas predichas a partir de las probabilidades de salida del modelo.\n",
    "results = np.argmax(predict,axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_uuid": "9ff4b8968bee29140b94c864598230a4d9bc1a45"
   },
   "outputs": [],
   "source": [
    "# Creamos un DataFrame, \"submission\" que contiene dos columnas: \"ImageId\" y \"Label\". \n",
    "# La columna \"ImageId\" contiene los valores del rango del 1 al 28000 (indicando el número de imagen correspondiente), \n",
    "# La columna \"Label\" contiene las etiquetas predichas para cada imagen.\n",
    "submission = pd.DataFrame({\"ImageId\":range(1,28001),\"Label\":results})\n",
    "submission.to_csv(\"cnn_mnist.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_uuid": "0c14d1c3cb01c550b2d75c9afc3ab6eab50727a1"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageId</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27995</th>\n",
       "      <td>27996</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27996</th>\n",
       "      <td>27997</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27997</th>\n",
       "      <td>27998</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27998</th>\n",
       "      <td>27999</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27999</th>\n",
       "      <td>28000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>28000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       ImageId  Label\n",
       "0            1      2\n",
       "1            2      0\n",
       "2            3      9\n",
       "3            4      9\n",
       "4            5      3\n",
       "...        ...    ...\n",
       "27995    27996      9\n",
       "27996    27997      7\n",
       "27997    27998      3\n",
       "27998    27999      9\n",
       "27999    28000      2\n",
       "\n",
       "[28000 rows x 2 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Publicamos en pantalla el DataFrame \"submission\".\n",
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
